# GridWatch NetEnterprise - Docker Compose Development Environment
# Usage:
#   Full stack:     docker compose up -d
#   IPAM only:      docker compose --profile ipam up -d
#   NPM only:       docker compose --profile npm up -d
#   STIG only:      docker compose --profile stig up -d
#   Syslog only:    docker compose --profile syslog up -d
#   Infrastructure: docker compose --profile infra up -d

name: gridwatch-net-enterprise

x-logging: &default-logging
  driver: "json-file"
  options:
    max-size: "10m"
    max-file: "3"

x-healthcheck-defaults: &healthcheck-defaults
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 40s

services:
  # ============================================
  # SHARED INFRASTRUCTURE
  # ============================================

  postgres:
    image: postgres:15-alpine
    profiles: ["infra", "ipam", "npm", "stig", "syslog"]
    container_name: gridwatch-postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-gridwatch}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:?Database password required}
      POSTGRES_DB: ${POSTGRES_DB:-gridwatch}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./infrastructure/postgres/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    ports:
      # Bind to localhost only - prevents external access to database
      - "127.0.0.1:5433:5432"
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-gridwatch}"]
    logging: *default-logging
    networks:
      - gridwatch-network

  redis:
    image: redis:7-alpine
    profiles: ["infra", "ipam", "npm", "stig", "syslog"]
    container_name: gridwatch-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:?Redis password required}
    volumes:
      - redis_data:/data
    ports:
      # Bind to localhost only - prevents external access to cache
      - "127.0.0.1:6379:6379"
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", "ping"]
    logging: *default-logging
    networks:
      - gridwatch-network

  nats:
    image: nats:2.10-alpine
    profiles: ["infra", "ipam", "npm", "stig", "syslog"]
    container_name: gridwatch-nats
    restart: unless-stopped
    command:
      - "--jetstream"
      - "--store_dir=/data"
      # Port 8322 used instead of 8222 to avoid Windows Hyper-V reserved port range (8139-8238)
      - "--http_port=8322"
    volumes:
      - nats_data:/data
      - ./infrastructure/nats/nats.conf:/etc/nats/nats.conf:ro
    ports:
      # Bind to localhost only - prevents external access to message broker
      - "127.0.0.1:4222:4222" # Client connections
      - "127.0.0.1:8322:8322" # HTTP monitoring (port changed for Windows compatibility)
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8322/healthz"]
    logging: *default-logging
    networks:
      - gridwatch-network

  vault:
    image: hashicorp/vault:1.18
    profiles: ["infra", "ipam", "npm", "stig"]
    container_name: gridwatch-vault
    restart: unless-stopped
    # SEC-021: Minimum capabilities — IPC_LOCK required for mlock (secret protection)
    # SKIP_SETCAP=true disables Vault's internal setcap call (fails on WSL2/Docker Desktop)
    cap_drop:
      - ALL
    cap_add:
      - IPC_LOCK
      - SETGID
      - SETUID
    environment:
      VAULT_DEV_ROOT_TOKEN_ID: ${VAULT_DEV_TOKEN:-gridwatch-dev-token}
      VAULT_DEV_LISTEN_ADDRESS: "0.0.0.0:8200"
      SKIP_SETCAP: "true"
    ports:
      # Port 8300 mapped externally to avoid Windows Hyper-V reserved range (8139-8238)
      - "8300:8200"
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD", "sh", "-c", "VAULT_ADDR=http://127.0.0.1:8200 vault status"]
    logging: *default-logging
    networks:
      - gridwatch-network

  # ============================================
  # OBSERVABILITY STACK
  # ============================================

  victoriametrics:
    image: victoriametrics/victoria-metrics:v1.93.0
    profiles: ["infra", "ipam", "npm", "stig"]
    container_name: gridwatch-victoriametrics
    restart: unless-stopped
    command:
      - "--storageDataPath=/victoria-metrics-data"
      - "--retentionPeriod=90d"
      - "--httpListenAddr=:8428"
    volumes:
      - victoriametrics_data:/victoria-metrics-data
    ports:
      # Bind to localhost only - use reverse proxy for external access in production
      - "127.0.0.1:8428:8428"
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD", "wget", "--spider", "-q", "http://127.0.0.1:8428/health"]
    logging: *default-logging
    networks:
      - gridwatch-network

  prometheus:
    image: prom/prometheus:v2.48.0
    profiles: ["infra", "ipam", "npm", "stig"]
    container_name: gridwatch-prometheus
    restart: unless-stopped
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.enable-lifecycle"
    volumes:
      - ./infrastructure/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    ports:
      # Bind to localhost only - use reverse proxy for external access in production
      - "127.0.0.1:9090:9090"
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]
    logging: *default-logging
    networks:
      - gridwatch-network

  loki:
    image: grafana/loki:2.9.0
    profiles: ["infra", "ipam", "npm", "stig"]
    container_name: gridwatch-loki
    restart: unless-stopped
    command: -config.file=/etc/loki/loki.yml
    volumes:
      - ./infrastructure/loki/loki.yml:/etc/loki/loki.yml:ro
      - loki_data:/loki
    ports:
      # Bind to localhost only - use reverse proxy for external access in production
      - "127.0.0.1:3100:3100"
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3100/ready"]
    logging: *default-logging
    networks:
      - gridwatch-network

  promtail:
    image: grafana/promtail:2.9.0
    profiles: ["infra", "ipam", "npm", "stig"]
    container_name: gridwatch-promtail
    restart: unless-stopped
    volumes:
      - ./infrastructure/promtail/promtail.yml:/etc/promtail/promtail.yml:ro
      - /var/log:/var/log:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    command: -config.file=/etc/promtail/promtail.yml
    depends_on:
      - loki
    logging: *default-logging
    networks:
      - gridwatch-network

  jaeger:
    image: jaegertracing/all-in-one:1.51
    profiles: ["infra", "ipam", "npm", "stig"]
    container_name: gridwatch-jaeger
    restart: unless-stopped
    environment:
      COLLECTOR_OTLP_ENABLED: "true"
    ports:
      # Bind to localhost only - use reverse proxy for external access in production
      - "127.0.0.1:16686:16686" # UI
      - "127.0.0.1:4317:4317" # OTLP gRPC
      - "127.0.0.1:4318:4318" # OTLP HTTP
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:16686/"]
    logging: *default-logging
    networks:
      - gridwatch-network

  grafana:
    image: grafana/grafana:11.4.0
    profiles: ["infra", "ipam", "npm", "stig"]
    container_name: gridwatch-grafana
    restart: unless-stopped
    environment:
      GF_SECURITY_ADMIN_USER: ${GRAFANA_USER:-admin}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:?Grafana password required}
      GF_USERS_ALLOW_SIGN_UP: "false"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./infrastructure/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./infrastructure/grafana/dashboards:/var/lib/grafana/dashboards:ro
    ports:
      # Bind to localhost only - use reverse proxy for external access in production
      - "127.0.0.1:${GRAFANA_PORT:-3002}:3000"
    depends_on:
      - prometheus
      - loki
      - victoriametrics
    healthcheck:
      <<: *healthcheck-defaults
      test:
        ["CMD", "wget", "--spider", "-q", "http://localhost:3000/api/health"]
    logging: *default-logging
    networks:
      - gridwatch-network

  # ============================================
  # APPLICATION SERVICES
  # ============================================

  gateway:
    build:
      context: .
      dockerfile: apps/gateway/Dockerfile
      target: development
    profiles: ["ipam", "npm", "stig"]
    container_name: gridwatch-gateway
    restart: unless-stopped
    # SEC-021: No elevated capabilities needed
    cap_drop:
      - ALL
    # NMAP Fingerprinting Note: To enable MAC address detection for hosts on your
    # physical LAN, uncomment 'network_mode: host' below and comment out the
    # 'networks' and 'ports' sections. Host network mode gives the container direct
    # Layer 2 access to the host's network interfaces. This is required because
    # MAC addresses can only be detected for hosts on the same network segment.
    # network_mode: host
    environment:
      NODE_ENV: development
      PORT: 3001
      POSTGRES_URL: postgresql://${POSTGRES_USER:-gridwatch}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-gridwatch}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      NATS_URL: nats://nats:4222
      VAULT_ADDR: http://vault:8200
      VAULT_TOKEN: ${VAULT_DEV_TOKEN:-gridwatch-dev-token}
      JAEGER_ENDPOINT: http://jaeger:4318/v1/traces
      AUTH_SERVICE_URL: http://auth-service:3006
      STIG_SERVICE_URL: http://stig-service:3005
      JWT_SECRET: ${JWT_SECRET:-gridwatch-dev-jwt-secret-2025}
      CREDENTIAL_ENCRYPTION_KEY: ${CREDENTIAL_ENCRYPTION_KEY:-gridwatch-dev-encryption-key-32ch}
      # Rate limiting - relaxed for development/E2E testing
      RATE_LIMIT_MAX: ${RATE_LIMIT_MAX:-1000}
      RATE_LIMIT_AUTH_MAX: ${RATE_LIMIT_AUTH_MAX:-500}
      RATE_LIMIT_WINDOW_MS: ${RATE_LIMIT_WINDOW_MS:-60000}
    volumes:
      - ./apps/gateway/src:/app/src:ro
      - ./packages:/packages
    ports:
      - "3001:3001"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      nats:
        condition: service_healthy
      auth-service:
        condition: service_healthy
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD", "wget", "--spider", "-q", "http://127.0.0.1:3001/healthz"]
    logging: *default-logging
    networks:
      - gridwatch-network

  auth-service:
    build:
      context: .
      dockerfile: services/auth-service/Dockerfile
      target: development
    profiles: ["ipam", "npm", "stig"]
    container_name: gridwatch-auth-service
    restart: unless-stopped
    cap_drop:
      - ALL
    environment:
      NODE_ENV: development
      PORT: 3006
      HOST: "0.0.0.0"
      POSTGRES_URL: postgresql://${POSTGRES_USER:-gridwatch}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-gridwatch}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      JWT_SECRET: ${JWT_SECRET:-gridwatch-dev-jwt-secret-2025}
      JWT_ACCESS_EXPIRY: "15m"
      JWT_REFRESH_EXPIRY: "7d"
      LOG_LEVEL: debug
    volumes:
      - ./services/auth-service/src:/app/src:ro
      - ./packages:/packages
    ports:
      - "3006:3006"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD", "wget", "--spider", "-q", "http://127.0.0.1:3006/healthz"]
    logging: *default-logging
    networks:
      - gridwatch-network

  web-ui:
    build:
      context: .
      dockerfile: apps/web-ui/Dockerfile
      target: development
    profiles: ["ipam", "npm", "stig"]
    container_name: gridwatch-web-ui
    restart: unless-stopped
    environment:
      VITE_API_URL: http://localhost:3001
    volumes:
      - ./apps/web-ui/src:/app/src:ro
      - ./apps/web-ui/public:/app/public:ro
      - ./apps/web-ui/index.html:/app/index.html:ro
      - ./apps/web-ui/vite.config.ts:/app/vite.config.ts:ro
      - ./apps/web-ui/tailwind.config.js:/app/tailwind.config.js:ro
      - ./apps/web-ui/postcss.config.js:/app/postcss.config.js:ro
      - ./apps/web-ui/tsconfig.json:/app/tsconfig.json:ro
      - ./apps/web-ui/tsconfig.node.json:/app/tsconfig.node.json:ro
      - ./packages/shared-ui:/packages/shared-ui
      - ./packages/shared-types:/packages/shared-types
    ports:
      - "3000:3000"
    depends_on:
      - gateway
    logging: *default-logging
    networks:
      - gridwatch-network

  # ============================================
  # IPAM SERVICES
  # ============================================

  ipam-service:
    build:
      context: ./apps/ipam
      dockerfile: Dockerfile
      target: development
    profiles: ["ipam"]
    container_name: gridwatch-ipam-service
    restart: unless-stopped
    cap_drop:
      - ALL
    environment:
      NODE_ENV: development
      IPAM_HOST: "0.0.0.0"
      IPAM_PORT: "3003"
      POSTGRES_URL: postgresql://${POSTGRES_USER:-gridwatch}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-gridwatch}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      NATS_URL: nats://nats:4222
      VAULT_ADDR: http://vault:8200
      VAULT_TOKEN: ${VAULT_DEV_TOKEN:-gridwatch-dev-token}
      JWT_SECRET: ${JWT_SECRET:-gridwatch-dev-jwt-secret-2025}
      VICTORIA_METRICS_URL: http://victoriametrics:8428
      LOG_LEVEL: DEBUG
    volumes:
      - ./apps/ipam/src:/app/src:ro
    ports:
      - "3003:3003"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      nats:
        condition: service_healthy
    healthcheck:
      <<: *healthcheck-defaults
      test:
        [
          "CMD",
          "python",
          "-c",
          "import httpx; httpx.get('http://localhost:3003/healthz').raise_for_status()",
        ]
    logging: *default-logging
    networks:
      - gridwatch-network

  ipam-scanner:
    build:
      context: ./apps/ipam
      dockerfile: Dockerfile
      target: scanner
    profiles: ["ipam"]
    container_name: gridwatch-ipam-scanner
    restart: unless-stopped
    environment:
      POSTGRES_URL: postgresql://${POSTGRES_USER:-gridwatch}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-gridwatch}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      NATS_URL: nats://nats:4222
      VAULT_ADDR: http://vault:8200
      VAULT_TOKEN: ${VAULT_DEV_TOKEN:-gridwatch-dev-token}
      JWT_SECRET: ${JWT_SECRET:-gridwatch-dev-jwt-secret-2025}
      VICTORIA_METRICS_URL: http://victoriametrics:8428
      SCAN_CONCURRENCY: "50"
      PING_TIMEOUT: "1.0"
    volumes:
      - ./apps/ipam/src:/app/src:ro
    depends_on:
      postgres:
        condition: service_healthy
      nats:
        condition: service_healthy
    # SEC-021: Minimum capabilities — NET_RAW for ICMP ping/nmap (NET_ADMIN removed)
    cap_drop:
      - ALL
    cap_add:
      - NET_RAW
    logging: *default-logging
    networks:
      - gridwatch-network

  # ============================================
  # NPM SERVICES
  # ============================================

  npm-service:
    build:
      context: ./apps/npm
      dockerfile: Dockerfile
      target: development
    profiles: ["npm"]
    container_name: gridwatch-npm-service
    restart: unless-stopped
    cap_drop:
      - ALL
    environment:
      NODE_ENV: development
      NPM_HOST: "0.0.0.0"
      NPM_PORT: "3004"
      POSTGRES_URL: postgresql://${POSTGRES_USER:-gridwatch}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-gridwatch}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      NATS_URL: nats://nats:4222
      VAULT_ADDR: http://vault:8200
      VAULT_TOKEN: ${VAULT_DEV_TOKEN:-gridwatch-dev-token}
      JWT_SECRET: ${JWT_SECRET:-gridwatch-dev-jwt-secret-2025}
      NPM_CREDENTIAL_KEY: ${CREDENTIAL_ENCRYPTION_KEY:-gridwatch-dev-encryption-key-32ch}
      VICTORIAMETRICS_URL: http://victoriametrics:8428
      LOG_LEVEL: DEBUG
    volumes:
      - ./apps/npm/src:/app/src:ro
    ports:
      - "3004:3004"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      nats:
        condition: service_healthy
    healthcheck:
      <<: *healthcheck-defaults
      test:
        [
          "CMD",
          "python",
          "-c",
          "import httpx; httpx.get('http://localhost:3004/healthz').raise_for_status()",
        ]
    logging: *default-logging
    networks:
      - gridwatch-network

  npm-collector:
    build:
      context: ./apps/npm
      dockerfile: Dockerfile
      target: collector
    profiles: ["npm"]
    container_name: gridwatch-npm-collector
    restart: unless-stopped
    cap_drop:
      - ALL
    environment:
      POSTGRES_URL: postgresql://${POSTGRES_USER:-gridwatch}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-gridwatch}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      NATS_URL: nats://nats:4222
      VICTORIAMETRICS_URL: http://victoriametrics:8428
      VAULT_ADDR: http://vault:8200
      NPM_CREDENTIAL_KEY: ${CREDENTIAL_ENCRYPTION_KEY:-gridwatch-dev-encryption-key-32ch}
    volumes:
      - ./apps/npm/collectors:/app/collectors:ro
    depends_on:
      postgres:
        condition: service_healthy
      nats:
        condition: service_healthy
      victoriametrics:
        condition: service_healthy
    logging: *default-logging
    networks:
      - gridwatch-network

  npm-alerts:
    build:
      context: ./apps/npm
      dockerfile: Dockerfile
      target: alerts
    profiles: ["npm"]
    container_name: gridwatch-npm-alerts
    restart: unless-stopped
    cap_drop:
      - ALL
    environment:
      POSTGRES_URL: postgresql://${POSTGRES_USER:-gridwatch}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-gridwatch}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      NATS_URL: nats://nats:4222
      VAULT_ADDR: http://vault:8200
      NPM_CREDENTIAL_KEY: ${CREDENTIAL_ENCRYPTION_KEY:-gridwatch-dev-encryption-key-32ch}
    volumes:
      - ./apps/npm/alerts:/app/alerts:ro
    depends_on:
      postgres:
        condition: service_healthy
      nats:
        condition: service_healthy
    logging: *default-logging
    networks:
      - gridwatch-network

  # ============================================
  # STIG MANAGER SERVICES
  # ============================================

  stig-service:
    build:
      context: ./apps/stig
      dockerfile: Dockerfile
      target: development
    profiles: ["stig"]
    container_name: gridwatch-stig-service
    restart: unless-stopped
    cap_drop:
      - ALL
    environment:
      NODE_ENV: development
      STIG_HOST: "0.0.0.0"
      STIG_PORT: "3005"
      POSTGRES_URL: postgresql://${POSTGRES_USER:-gridwatch}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-gridwatch}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      NATS_URL: nats://nats:4222
      VAULT_ADDR: http://vault:8200
      VAULT_TOKEN: ${VAULT_DEV_TOKEN:-gridwatch-dev-token}
      JWT_SECRET: ${JWT_SECRET:-gridwatch-dev-jwt-secret-2025}
      REPORT_OUTPUT_DIR: /app/output
      LOG_LEVEL: DEBUG
      STIG_LIBRARY_PATH: /app/stig-library
    volumes:
      - ./apps/stig/src:/app/src:ro
      - stig_reports:/app/output
      - ./STIG/Library/U_SRG-STIG_Library_October_2025:/app/stig-library:ro
    ports:
      - "3005:3005"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      nats:
        condition: service_healthy
    healthcheck:
      <<: *healthcheck-defaults
      test:
        [
          "CMD",
          "python",
          "-c",
          "import httpx; httpx.get('http://localhost:3005/healthz').raise_for_status()",
        ]
    logging: *default-logging
    networks:
      - gridwatch-network

  stig-collector:
    build:
      context: ./apps/stig
      dockerfile: Dockerfile
      target: collector
    profiles: ["stig"]
    container_name: gridwatch-stig-collector
    restart: unless-stopped
    cap_drop:
      - ALL
    environment:
      POSTGRES_URL: postgresql://${POSTGRES_USER:-gridwatch}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-gridwatch}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      NATS_URL: nats://nats:4222
      VAULT_ADDR: http://vault:8200
      JWT_SECRET: ${JWT_SECRET:-gridwatch-dev-jwt-secret-2025}
    volumes:
      - ./apps/stig/collectors:/app/collectors:ro
    depends_on:
      postgres:
        condition: service_healthy
      nats:
        condition: service_healthy
    logging: *default-logging
    networks:
      - gridwatch-network

  stig-reports:
    build:
      context: ./apps/stig
      dockerfile: Dockerfile
      target: reports
    profiles: ["stig"]
    container_name: gridwatch-stig-reports
    restart: unless-stopped
    cap_drop:
      - ALL
    environment:
      POSTGRES_URL: postgresql://${POSTGRES_USER:-gridwatch}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-gridwatch}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      NATS_URL: nats://nats:4222
      VAULT_ADDR: http://vault:8200
      JWT_SECRET: ${JWT_SECRET:-gridwatch-dev-jwt-secret-2025}
    volumes:
      - ./apps/stig/reports:/app/reports:ro
      - stig_reports:/app/output
    depends_on:
      postgres:
        condition: service_healthy
      nats:
        condition: service_healthy
    logging: *default-logging
    networks:
      - gridwatch-network

  # ============================================
  # SYSLOG SERVICES
  # ============================================

  syslog-service:
    build:
      context: ./apps/syslog
      dockerfile: Dockerfile
      target: development
    profiles: ["syslog"]
    container_name: gridwatch-syslog-service
    restart: unless-stopped
    cap_drop:
      - ALL
    environment:
      NODE_ENV: development
      SYSLOG_HOST: "0.0.0.0"
      SYSLOG_PORT: "3007"
      POSTGRES_URL: postgresql://${POSTGRES_USER:-gridwatch}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-gridwatch}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      NATS_URL: nats://nats:4222
      LOG_LEVEL: DEBUG
    volumes:
      - ./apps/syslog/src:/app/src:ro
    ports:
      - "3007:3007"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      nats:
        condition: service_healthy
    healthcheck:
      <<: *healthcheck-defaults
      test:
        [
          "CMD",
          "python",
          "-c",
          "import httpx; httpx.get('http://localhost:3007/healthz').raise_for_status()",
        ]
    logging: *default-logging
    networks:
      - gridwatch-network

  syslog-collector:
    build:
      context: ./apps/syslog
      dockerfile: Dockerfile
      target: collector
    profiles: ["syslog"]
    container_name: gridwatch-syslog-collector
    restart: unless-stopped
    # NOTE: On Windows/WSL2, network_mode:host doesn't work as expected.
    # Docker NAT will translate source IPs to bridge gateway (172.30.0.1).
    # Configure syslog sources to match the NAT'd IP, or use hostname from syslog message.
    # For Linux hosts, uncomment network_mode: host below for real source IPs.
    # network_mode: host
    environment:
      POSTGRES_URL: postgresql://${POSTGRES_USER:-gridwatch}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-gridwatch}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      NATS_URL: nats://nats:4222
      SYSLOG_UDP_PORT: "514"
      LOG_LEVEL: INFO
    volumes:
      - ./apps/syslog/src:/app/src:ro
    ports:
      - "514:514/udp" # UDP syslog
      - "514:514/tcp" # TCP syslog
    depends_on:
      postgres:
        condition: service_healthy
      nats:
        condition: service_healthy
    # SEC-021: Minimum capabilities — NET_BIND_SERVICE for port 514
    cap_drop:
      - ALL
    cap_add:
      - NET_BIND_SERVICE
    logging: *default-logging
    networks:
      - gridwatch-network

  syslog-forwarder:
    build:
      context: ./apps/syslog
      dockerfile: Dockerfile
      target: forwarder
    profiles: ["syslog"]
    container_name: gridwatch-syslog-forwarder
    restart: unless-stopped
    cap_drop:
      - ALL
    environment:
      POSTGRES_URL: postgresql://${POSTGRES_USER:-gridwatch}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB:-gridwatch}
      REDIS_URL: redis://:${REDIS_PASSWORD}@redis:6379
      NATS_URL: nats://nats:4222
      LOG_LEVEL: INFO
    volumes:
      - ./apps/syslog/src:/app/src:ro
    depends_on:
      postgres:
        condition: service_healthy
      nats:
        condition: service_healthy
    logging: *default-logging
    networks:
      - gridwatch-network

  # ============================================
  # REVERSE PROXY (Production)
  # ============================================

  nginx:
    image: nginx:1.25-alpine
    profiles: ["prod"]
    container_name: gridwatch-nginx
    restart: unless-stopped
    volumes:
      - ./infrastructure/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./infrastructure/nginx/ssl:/etc/nginx/ssl:ro
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - gateway
      - web-ui
    healthcheck:
      <<: *healthcheck-defaults
      test: ["CMD", "nginx", "-t"]
    logging: *default-logging
    networks:
      - gridwatch-network

# ============================================
# VOLUMES
# ============================================

volumes:
  postgres_data:
    name: gridwatch-postgres-data
  redis_data:
    name: gridwatch-redis-data
  nats_data:
    name: gridwatch-nats-data
  victoriametrics_data:
    name: gridwatch-victoriametrics-data
  prometheus_data:
    name: gridwatch-prometheus-data
  loki_data:
    name: gridwatch-loki-data
  grafana_data:
    name: gridwatch-grafana-data
  stig_reports:
    name: gridwatch-stig-reports

# ============================================
# NETWORKS
# ============================================

networks:
  gridwatch-network:
    name: gridwatch-network
    driver: bridge
    ipam:
      config:
        - subnet: 172.30.0.0/16
